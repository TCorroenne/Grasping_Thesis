{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac02b048-a4e9-4136-bdf4-3f092314f654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported everything\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import tensorboardX\n",
    "\n",
    "from utility import train_utility\n",
    "\n",
    "from utility.data import get_custom_dataset\n",
    "from utility.peggnet_model import PEGG_NET\n",
    "import utility.io_processing as iop\n",
    "print(\"imported everything\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417d3214-8ca1-4817-820e-674279bffcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net: PEGG_NET, device, val_data: torch.utils.data.DataLoader, use_sparse_loss=False):\n",
    "    \"\"\"\n",
    "    Run validation.\n",
    "    :param net: Network\n",
    "    :param device: Torch device\n",
    "    :param val_data: Validation Dataset\n",
    "    :param batches_per_epoch: Number of batches to run\n",
    "    :return: Successes, Failures and Losses\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "\n",
    "    results = {\n",
    "        'correct': 0,\n",
    "        'failed': 0,\n",
    "        'loss': 0,\n",
    "        'losses': {\n",
    "\n",
    "        }\n",
    "    }\n",
    "\n",
    "    ld = len(val_data)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, didx, rot, zoom_factor, score, angle_at_fault in val_data:\n",
    "\n",
    "            xc = x.to(device)\n",
    "            yc = [yy.to(device) for yy in y]\n",
    "            if use_sparse_loss:\n",
    "                lossd = net.compute_loss_sparse(xc, yc, angle_at_fault=angle_at_fault, score=score, score_min_mask=0)\n",
    "            else:\n",
    "                lossd = net.compute_loss(xc, yc)\n",
    "\n",
    "            loss = lossd['loss']\n",
    "\n",
    "            results['loss'] += loss.item()/ld\n",
    "            for ln, l in lossd['losses'].items():\n",
    "                if ln not in results['losses']:\n",
    "                    results['losses'][ln] = 0\n",
    "                results['losses'][ln] += l.item()/ld\n",
    "\n",
    "            q_out, ang_out, w_out = iop.process_raw_output(lossd['pred']['pos'], lossd['pred']['cos'],\n",
    "                                                        lossd['pred']['sin'], lossd['pred']['width'])\n",
    "            # logging.info('rot, zoom : {},{}'.format(rot, zoom_factor)) #Its 2 tensors of size 1\n",
    "            s = train_utility.calculate_iou_match(q_out, ang_out,\n",
    "                                                val_data.dataset.get_gtbb(didx, 0, 1.0),\n",
    "                                                no_grasps=1,\n",
    "                                                grasp_width=w_out,\n",
    "                                                )\n",
    "\n",
    "            if s:\n",
    "                results['correct'] += 1\n",
    "            else:\n",
    "                results['failed'] += 1\n",
    "    return results\n",
    "\n",
    "def train(epoch: int, net: PEGG_NET, device, train_data: torch.utils.data.DataLoader, optimizer: optim.Adam, batches_per_epoch, vis=False):\n",
    "    \"\"\"\n",
    "    Run one training epoch\n",
    "    :param epoch: Current epoch\n",
    "    :param net: Network\n",
    "    :param device: Torch device\n",
    "    :param train_data: Training Dataset\n",
    "    :param optimizer: Optimizer\n",
    "    :param batches_per_epoch:  Data batches to train on\n",
    "    :param vis:  Visualise training progress\n",
    "    :return:  Average Losses for Epoch\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'loss': 0,\n",
    "        'losses': {\n",
    "        }\n",
    "    }\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    batch_idx = 0\n",
    "    # Use batches per epoch to make training on different sized datasets (cornell/jacquard) more equivalent.\n",
    "    while batch_idx < batches_per_epoch:\n",
    "        # logging.info('batch_idx: {}'.format(batch_idx))\n",
    "        for x, y, _, _, _, score, angle_at_fault in train_data:\n",
    "            batch_idx += 1\n",
    "            if batch_idx >= batches_per_epoch:\n",
    "                break\n",
    "\n",
    "            xc = x.to(device)\n",
    "            yc = [yy.to(device) for yy in y]\n",
    "            lossd = net.compute_loss_sparse(xc, yc, angle_at_fault=angle_at_fault, score=score)\n",
    "\n",
    "            loss = lossd['loss']\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                logging.info('Epoch: {}, Batch: {}, Loss: {:0.4f}'.format(epoch, batch_idx, loss.item()))\n",
    "\n",
    "            results['loss'] += loss.item()\n",
    "            for ln, l in lossd['losses'].items():\n",
    "                if ln not in results['losses']:\n",
    "                    results['losses'][ln] = 0\n",
    "                results['losses'][ln] += l.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Display the images\n",
    "            # if vis:\n",
    "            #     imgs = []\n",
    "            #     n_img = min(4, x.shape[0])\n",
    "            #     for idx in range(n_img):\n",
    "            #         imgs.extend([x[idx,].numpy().squeeze()] + [yi[idx,].numpy().squeeze() for yi in y] + [\n",
    "            #             x[idx,].numpy().squeeze()] + [pc[idx,].detach().cpu().numpy().squeeze() for pc in lossd['pred'].values()])\n",
    "            #     gridshow('Display', imgs,\n",
    "            #              [(xc.min().item(), xc.max().item()), (0.0, 1.0), (0.0, 1.0), (-1.0, 1.0), (0.0, 1.0)] * 2 * n_img,\n",
    "            #              [cv2.COLORMAP_BONE] * 10 * n_img, 10)\n",
    "            #     cv2.waitKey(2)\n",
    "\n",
    "    results['loss'] /= batch_idx\n",
    "    for l in results['losses']:\n",
    "        results['losses'][l] /= batch_idx\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa7c648-9acb-4ca8-9d47-4391c368cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "state_dict = \"saved_models/baseline_peggnet/epoch_17_iou_0.91_statedict.pt\"\n",
    "network = \"peggnet\"\n",
    "input_size = 480\n",
    "max_width = 150\n",
    "dataset = \"custom\"\n",
    "dataset_train = \"training/training\"\n",
    "dataset_eval_sparse = \"training/validation_sparse\"\n",
    "dataset_eval_annotated = \"training/validation_annotated\"\n",
    "use_depth = True\n",
    "use_rgb = True\n",
    "\n",
    "# random_zoom = True\n",
    "# random_rotations = True\n",
    "# random_symmetry=True\n",
    "# random_brightness=True\n",
    "# random_contrast=True\n",
    "force_save_every = 1\n",
    "\n",
    "split = 1.0\n",
    "ds_rotate = 0.0\n",
    "image_wise = False\n",
    "random_seed = 10\n",
    "augment = True\n",
    "num_workers = 8\n",
    "\n",
    "lr = 0.001\n",
    "lr_step = [10,20,30,40]\n",
    "lr_step_coeff = 0.8\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "batches_per_epoch = 1000\n",
    "\n",
    "description = \"\"\n",
    "outdir = \"output/models\"\n",
    "logdir = \"tensorboard/\"\n",
    "vis = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a8ee48-9de8-4a51-9305-4f00f54d61a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading Custom Dataset...\n",
      "INFO:root:Done\n",
      "INFO:root:Number of training images: 265\n",
      "INFO:root:Number of sparse validation images: 20\n",
      "INFO:root:Number of annotated validation images: 40\n",
      "INFO:root:Data augmentation (for training only): True\n",
      "INFO:root:Loading Network...\n",
      "INFO:root:Number of input channels: 4\n",
      "INFO:root:Using device: cuda\n",
      "/tmp/ipykernel_3098/725869730.py:100: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(state_dict, map_location=device))\n",
      "INFO:root:Network Loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 480, 480]           1,152\n",
      "       BatchNorm2d-2         [-1, 32, 480, 480]              64\n",
      "              Mish-3         [-1, 32, 480, 480]               0\n",
      "Conv_Bn_Activation-4         [-1, 32, 480, 480]               0\n",
      "            Conv2d-5         [-1, 32, 480, 480]           1,024\n",
      "       BatchNorm2d-6         [-1, 32, 480, 480]              64\n",
      "              Mish-7         [-1, 32, 480, 480]               0\n",
      "Conv_Bn_Activation-8         [-1, 32, 480, 480]               0\n",
      "            Conv2d-9         [-1, 32, 480, 480]           9,216\n",
      "      BatchNorm2d-10         [-1, 32, 480, 480]              64\n",
      "             Mish-11         [-1, 32, 480, 480]               0\n",
      "Conv_Bn_Activation-12         [-1, 32, 480, 480]               0\n",
      "         ResBlock-13         [-1, 32, 480, 480]               0\n",
      "           Conv2d-14         [-1, 64, 240, 240]          18,432\n",
      "      BatchNorm2d-15         [-1, 64, 240, 240]             128\n",
      "             Mish-16         [-1, 64, 240, 240]               0\n",
      "Conv_Bn_Activation-17         [-1, 64, 240, 240]               0\n",
      "           Conv2d-18         [-1, 64, 240, 240]           4,096\n",
      "      BatchNorm2d-19         [-1, 64, 240, 240]             128\n",
      "             Mish-20         [-1, 64, 240, 240]               0\n",
      "Conv_Bn_Activation-21         [-1, 64, 240, 240]               0\n",
      "           Conv2d-22         [-1, 64, 240, 240]          36,864\n",
      "      BatchNorm2d-23         [-1, 64, 240, 240]             128\n",
      "             Mish-24         [-1, 64, 240, 240]               0\n",
      "Conv_Bn_Activation-25         [-1, 64, 240, 240]               0\n",
      "         ResBlock-26         [-1, 64, 240, 240]               0\n",
      "           Conv2d-27        [-1, 128, 120, 120]          73,728\n",
      "      BatchNorm2d-28        [-1, 128, 120, 120]             256\n",
      "             Mish-29        [-1, 128, 120, 120]               0\n",
      "Conv_Bn_Activation-30        [-1, 128, 120, 120]               0\n",
      "           Conv2d-31        [-1, 128, 120, 120]          16,384\n",
      "      BatchNorm2d-32        [-1, 128, 120, 120]             256\n",
      "             Mish-33        [-1, 128, 120, 120]               0\n",
      "Conv_Bn_Activation-34        [-1, 128, 120, 120]               0\n",
      "           Conv2d-35        [-1, 128, 120, 120]         147,456\n",
      "      BatchNorm2d-36        [-1, 128, 120, 120]             256\n",
      "             Mish-37        [-1, 128, 120, 120]               0\n",
      "Conv_Bn_Activation-38        [-1, 128, 120, 120]               0\n",
      "         ResBlock-39        [-1, 128, 120, 120]               0\n",
      "           Conv2d-40          [-1, 256, 60, 60]         294,912\n",
      "      BatchNorm2d-41          [-1, 256, 60, 60]             512\n",
      "             Mish-42          [-1, 256, 60, 60]               0\n",
      "Conv_Bn_Activation-43          [-1, 256, 60, 60]               0\n",
      "           Conv2d-44          [-1, 256, 60, 60]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 60, 60]             512\n",
      "             Mish-46          [-1, 256, 60, 60]               0\n",
      "Conv_Bn_Activation-47          [-1, 256, 60, 60]               0\n",
      "           Conv2d-48          [-1, 128, 60, 60]          32,768\n",
      "      BatchNorm2d-49          [-1, 128, 60, 60]             256\n",
      "             Mish-50          [-1, 128, 60, 60]               0\n",
      "Conv_Bn_Activation-51          [-1, 128, 60, 60]               0\n",
      "        MaxPool2d-52          [-1, 128, 60, 60]               0\n",
      "        MaxPool2d-53          [-1, 128, 60, 60]               0\n",
      "        MaxPool2d-54          [-1, 128, 60, 60]               0\n",
      "              SPP-55          [-1, 512, 60, 60]               0\n",
      "           Conv2d-56          [-1, 256, 60, 60]         131,072\n",
      "      BatchNorm2d-57          [-1, 256, 60, 60]             512\n",
      "             Mish-58          [-1, 256, 60, 60]               0\n",
      "Conv_Bn_Activation-59          [-1, 256, 60, 60]               0\n",
      "     PixelShuffle-60        [-1, 128, 120, 120]               0\n",
      "           Conv2d-61        [-1, 128, 120, 120]          16,384\n",
      "      BatchNorm2d-62        [-1, 128, 120, 120]             256\n",
      "             Mish-63        [-1, 128, 120, 120]               0\n",
      "Conv_Bn_Activation-64        [-1, 128, 120, 120]               0\n",
      "     PixelShuffle-65         [-1, 64, 240, 240]               0\n",
      "           Conv2d-66         [-1, 64, 240, 240]           4,096\n",
      "      BatchNorm2d-67         [-1, 64, 240, 240]             128\n",
      "             Mish-68         [-1, 64, 240, 240]               0\n",
      "Conv_Bn_Activation-69         [-1, 64, 240, 240]               0\n",
      "     PixelShuffle-70         [-1, 32, 480, 480]               0\n",
      "           Conv2d-71         [-1, 32, 480, 480]           1,024\n",
      "      BatchNorm2d-72         [-1, 32, 480, 480]              64\n",
      "             ReLU-73         [-1, 32, 480, 480]               0\n",
      "Conv_Bn_Activation-74         [-1, 32, 480, 480]               0\n",
      "           Conv2d-75          [-1, 1, 480, 480]             577\n",
      "           Conv2d-76          [-1, 1, 480, 480]             577\n",
      "           Conv2d-77          [-1, 1, 480, 480]             577\n",
      "           Conv2d-78          [-1, 1, 480, 480]             577\n",
      "================================================================\n",
      "Total params: 1,384,324\n",
      "Trainable params: 1,384,324\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.52\n",
      "Forward/backward pass size (MB): 1901.95\n",
      "Params size (MB): 5.28\n",
      "Estimated Total Size (MB): 1910.75\n",
      "----------------------------------------------------------------\n",
      "[10, 20, 30, 40]\n",
      "Drop LR to 0.0008\n",
      "[10, 20, 30, 40]\n",
      "Drop LR to 0.00064\n",
      "[10, 20, 30, 40]\n",
      "Drop LR to 0.0005120000000000001\n",
      "[10, 20, 30, 40]\n",
      "Drop LR to 0.0004096000000000001\n"
     ]
    }
   ],
   "source": [
    "# !!! USING CV2 VIS IN JUPYTER NOTEBOOK MAKE THE CORE CRASH\n",
    "# if vis:\n",
    "#     cv2.namedWindow('Display', cv2.WINDOW_NORMAL)\n",
    "\n",
    "\n",
    "# Set-up output directories\n",
    "dt = datetime.datetime.now().strftime('%y%m%d_%H%M')\n",
    "net_desc = '{}_{}'.format(dt, '_'.join(description.split()))\n",
    "save_folder = os.path.join(outdir, net_desc)\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "tb = tensorboardX.SummaryWriter(os.path.join(logdir, net_desc))\n",
    "# Load Dataset\n",
    "logging.info('Loading {} Dataset...'.format(dataset.title()))\n",
    "Dataset = get_custom_dataset(dataset)\n",
    "\n",
    "train_dataset = Dataset(file_path=dataset_train,\n",
    "                        output_size=input_size,\n",
    "                        start=0.0,\n",
    "                        end=split,\n",
    "                        ds_rotate=ds_rotate,\n",
    "                        image_wise=image_wise,\n",
    "                        random_seed=random_seed,\n",
    "                        random_rotate=augment,\n",
    "                        random_zoom=augment,\n",
    "                        random_symmetry=augment,\n",
    "                        random_brightness=augment,\n",
    "                        random_contrast=augment,\n",
    "                        include_depth=use_depth, \n",
    "                        include_rgb=use_rgb,\n",
    "                        max_width=max_width)\n",
    "train_data = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "val_dataset_sparse = Dataset(file_path=dataset_eval_sparse,\n",
    "                             output_size=input_size,\n",
    "                             start=0.0,\n",
    "                             end=1.0,\n",
    "                             ds_rotate=ds_rotate,\n",
    "                             image_wise=image_wise,\n",
    "                             random_seed=random_seed,\n",
    "                             random_rotate=False,\n",
    "                             random_zoom=False,\n",
    "                             random_symmetry=False,\n",
    "                             random_brightness=False,\n",
    "                             random_contrast=False,\n",
    "                             include_depth=use_depth,\n",
    "                             include_rgb=use_rgb,\n",
    "                             max_width=max_width)\n",
    "val_data_sparse = torch.utils.data.DataLoader(\n",
    "    val_dataset_sparse,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "val_dataset_annotated = Dataset(file_path=dataset_eval_annotated,\n",
    "                                output_size=input_size,\n",
    "                                start=0.0,\n",
    "                                end=1.0,\n",
    "                                ds_rotate=ds_rotate,\n",
    "                                image_wise=image_wise,\n",
    "                                random_seed=random_seed,\n",
    "                                random_rotate=False,\n",
    "                                random_zoom=False,\n",
    "                                random_symmetry=False,\n",
    "                                random_brightness=False,\n",
    "                                random_contrast=False,\n",
    "                                include_depth=use_depth,\n",
    "                                include_rgb=use_rgb,\n",
    "                                max_width=max_width)\n",
    "val_data_annotated = torch.utils.data.DataLoader(\n",
    "    val_dataset_annotated,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "logging.info('Done')\n",
    "logging.info('Number of training images: {}'.format(len(train_dataset)))\n",
    "logging.info('Number of sparse validation images: {}'.format(len(val_data_sparse)))\n",
    "logging.info('Number of annotated validation images: {}'.format(len(val_data_annotated)))\n",
    "logging.info('Data augmentation (for training only): {}'.format(augment))\n",
    "\n",
    "# Load the network\n",
    "logging.info('Loading Network...')\n",
    "input_channels = 1*use_depth + 3*use_rgb\n",
    "logging.info(\"Number of input channels: {}\".format(input_channels))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info('Using device: {}'.format(device))\n",
    "\n",
    "\n",
    "net = PEGG_NET(input_channels=input_channels)\n",
    "if model is not None:\n",
    "    net = torch.load(model, map_location=device)\n",
    "elif state_dict is not None:\n",
    "    net.load_state_dict(torch.load(state_dict, map_location=device, weights_only=True))\n",
    "net = net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "logging.info('Network Loaded')\n",
    "\n",
    "# Print model architecture.\n",
    "summary(net, (input_channels, input_size, input_size))\n",
    "f = open(os.path.join(save_folder, 'arch.txt'), 'w')\n",
    "sys.stdout = f\n",
    "summary(net, (input_channels, input_size, input_size))\n",
    "sys.stdout = sys.__stdout__\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f257d-527d-4104-a6c2-fa9c898051f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Beginning Epoch 01\n",
      "INFO:root:Epoch: 1, Batch: 100, Loss: 0.0975\n",
      "INFO:root:Epoch: 1, Batch: 200, Loss: 0.0731\n",
      "INFO:root:Epoch: 1, Batch: 300, Loss: 0.0591\n",
      "INFO:root:Epoch: 1, Batch: 400, Loss: 0.0336\n",
      "INFO:root:Epoch: 1, Batch: 500, Loss: 0.0334\n",
      "INFO:root:Epoch: 1, Batch: 600, Loss: 0.1120\n",
      "INFO:root:Epoch: 1, Batch: 700, Loss: 0.1081\n",
      "INFO:root:Epoch: 1, Batch: 800, Loss: 0.0345\n",
      "INFO:root:Epoch: 1, Batch: 900, Loss: 0.0606\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:10/20 = 0.500000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:32/40 = 0.800000\n",
      "INFO:root:Beginning Epoch 02\n",
      "INFO:root:Epoch: 2, Batch: 100, Loss: 0.0313\n",
      "INFO:root:Epoch: 2, Batch: 200, Loss: 0.1174\n",
      "INFO:root:Epoch: 2, Batch: 300, Loss: 0.0358\n",
      "INFO:root:Epoch: 2, Batch: 400, Loss: 0.0191\n",
      "INFO:root:Epoch: 2, Batch: 500, Loss: 0.1035\n",
      "INFO:root:Epoch: 2, Batch: 600, Loss: 0.0577\n",
      "INFO:root:Epoch: 2, Batch: 700, Loss: 0.0804\n",
      "INFO:root:Epoch: 2, Batch: 800, Loss: 0.0331\n",
      "INFO:root:Epoch: 2, Batch: 900, Loss: 0.1028\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:12/20 = 0.600000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:37/40 = 0.925000\n",
      "INFO:root:Beginning Epoch 03\n",
      "INFO:root:Epoch: 3, Batch: 100, Loss: 0.0685\n",
      "INFO:root:Epoch: 3, Batch: 200, Loss: 0.0230\n",
      "INFO:root:Epoch: 3, Batch: 300, Loss: 0.0300\n",
      "INFO:root:Epoch: 3, Batch: 400, Loss: 0.0403\n",
      "INFO:root:Epoch: 3, Batch: 500, Loss: 0.0208\n",
      "INFO:root:Epoch: 3, Batch: 600, Loss: 0.0625\n",
      "INFO:root:Epoch: 3, Batch: 700, Loss: 0.0384\n",
      "INFO:root:Epoch: 3, Batch: 800, Loss: 0.0655\n",
      "INFO:root:Epoch: 3, Batch: 900, Loss: 0.1261\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:10/20 = 0.500000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:33/40 = 0.825000\n",
      "INFO:root:Beginning Epoch 04\n",
      "INFO:root:Epoch: 4, Batch: 100, Loss: 0.0237\n",
      "INFO:root:Epoch: 4, Batch: 200, Loss: 0.1163\n",
      "INFO:root:Epoch: 4, Batch: 300, Loss: 0.0282\n",
      "INFO:root:Epoch: 4, Batch: 400, Loss: 0.0471\n",
      "INFO:root:Epoch: 4, Batch: 500, Loss: 0.0869\n",
      "INFO:root:Epoch: 4, Batch: 600, Loss: 0.0870\n",
      "INFO:root:Epoch: 4, Batch: 700, Loss: 0.0987\n",
      "INFO:root:Epoch: 4, Batch: 800, Loss: 0.0506\n",
      "INFO:root:Epoch: 4, Batch: 900, Loss: 0.0423\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:9/20 = 0.450000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:37/40 = 0.925000\n",
      "INFO:root:Beginning Epoch 05\n",
      "INFO:root:Epoch: 5, Batch: 100, Loss: 0.0416\n",
      "INFO:root:Epoch: 5, Batch: 200, Loss: 0.0232\n",
      "INFO:root:Epoch: 5, Batch: 300, Loss: 0.0859\n",
      "INFO:root:Epoch: 5, Batch: 400, Loss: 0.0949\n",
      "INFO:root:Epoch: 5, Batch: 500, Loss: 0.0465\n",
      "INFO:root:Epoch: 5, Batch: 600, Loss: 0.0299\n",
      "INFO:root:Epoch: 5, Batch: 700, Loss: 0.0464\n",
      "INFO:root:Epoch: 5, Batch: 800, Loss: 0.0291\n",
      "INFO:root:Epoch: 5, Batch: 900, Loss: 0.0987\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:13/20 = 0.650000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:39/40 = 0.975000\n",
      "INFO:root:Beginning Epoch 06\n",
      "INFO:root:Epoch: 6, Batch: 100, Loss: 0.0247\n",
      "INFO:root:Epoch: 6, Batch: 200, Loss: 0.1635\n",
      "INFO:root:Epoch: 6, Batch: 300, Loss: 0.1264\n",
      "INFO:root:Epoch: 6, Batch: 400, Loss: 0.0605\n",
      "INFO:root:Epoch: 6, Batch: 500, Loss: 0.0412\n",
      "INFO:root:Epoch: 6, Batch: 600, Loss: 0.0213\n",
      "INFO:root:Epoch: 6, Batch: 700, Loss: 0.1650\n",
      "INFO:root:Epoch: 6, Batch: 800, Loss: 0.1585\n",
      "INFO:root:Epoch: 6, Batch: 900, Loss: 0.0528\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:11/20 = 0.550000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:35/40 = 0.875000\n",
      "INFO:root:Beginning Epoch 07\n",
      "INFO:root:Epoch: 7, Batch: 100, Loss: 0.1652\n",
      "INFO:root:Epoch: 7, Batch: 200, Loss: 0.0500\n",
      "INFO:root:Epoch: 7, Batch: 300, Loss: 0.0539\n",
      "INFO:root:Epoch: 7, Batch: 400, Loss: 0.0546\n",
      "INFO:root:Epoch: 7, Batch: 500, Loss: 0.0490\n",
      "INFO:root:Epoch: 7, Batch: 600, Loss: 0.0457\n",
      "INFO:root:Epoch: 7, Batch: 700, Loss: 0.1416\n",
      "INFO:root:Epoch: 7, Batch: 800, Loss: 0.0959\n",
      "INFO:root:Epoch: 7, Batch: 900, Loss: 0.0487\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:12/20 = 0.600000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:33/40 = 0.825000\n",
      "INFO:root:Beginning Epoch 08\n",
      "INFO:root:Epoch: 8, Batch: 100, Loss: 0.0213\n",
      "INFO:root:Epoch: 8, Batch: 200, Loss: 0.0208\n",
      "INFO:root:Epoch: 8, Batch: 300, Loss: 0.0474\n",
      "INFO:root:Epoch: 8, Batch: 400, Loss: 0.0367\n",
      "INFO:root:Epoch: 8, Batch: 500, Loss: 0.0859\n",
      "INFO:root:Epoch: 8, Batch: 600, Loss: 0.0511\n",
      "INFO:root:Epoch: 8, Batch: 700, Loss: 0.0323\n",
      "INFO:root:Epoch: 8, Batch: 800, Loss: 0.0396\n",
      "INFO:root:Epoch: 8, Batch: 900, Loss: 0.0923\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:13/20 = 0.650000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:37/40 = 0.925000\n",
      "INFO:root:Beginning Epoch 09\n",
      "INFO:root:Epoch: 9, Batch: 100, Loss: 0.0870\n",
      "INFO:root:Epoch: 9, Batch: 200, Loss: 0.1051\n",
      "INFO:root:Epoch: 9, Batch: 300, Loss: 0.0302\n",
      "INFO:root:Epoch: 9, Batch: 400, Loss: 0.0363\n",
      "INFO:root:Epoch: 9, Batch: 500, Loss: 0.1130\n",
      "INFO:root:Epoch: 9, Batch: 600, Loss: 0.0426\n",
      "INFO:root:Epoch: 9, Batch: 700, Loss: 0.0422\n",
      "INFO:root:Epoch: 9, Batch: 800, Loss: 0.0492\n",
      "INFO:root:Epoch: 9, Batch: 900, Loss: 0.0827\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:10/20 = 0.500000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:37/40 = 0.925000\n",
      "INFO:root:Beginning Epoch 10\n",
      "INFO:root:Epoch: 10, Batch: 100, Loss: 0.0298\n",
      "INFO:root:Epoch: 10, Batch: 200, Loss: 0.0280\n",
      "INFO:root:Epoch: 10, Batch: 300, Loss: 0.0273\n",
      "INFO:root:Epoch: 10, Batch: 400, Loss: 0.0322\n",
      "INFO:root:Epoch: 10, Batch: 500, Loss: 0.0973\n",
      "INFO:root:Epoch: 10, Batch: 600, Loss: 0.0261\n",
      "INFO:root:Epoch: 10, Batch: 700, Loss: 0.0199\n",
      "INFO:root:Epoch: 10, Batch: 800, Loss: 0.0945\n",
      "INFO:root:Epoch: 10, Batch: 900, Loss: 0.1096\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:11/20 = 0.550000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:34/40 = 0.850000\n",
      "INFO:root:Beginning Epoch 11\n",
      "INFO:root:Epoch: 11, Batch: 100, Loss: 0.0484\n",
      "INFO:root:Epoch: 11, Batch: 200, Loss: 0.0299\n",
      "INFO:root:Epoch: 11, Batch: 300, Loss: 0.0421\n",
      "INFO:root:Epoch: 11, Batch: 400, Loss: 0.1710\n",
      "INFO:root:Epoch: 11, Batch: 500, Loss: 0.0610\n",
      "INFO:root:Epoch: 11, Batch: 600, Loss: 0.0517\n",
      "INFO:root:Epoch: 11, Batch: 700, Loss: 0.0511\n",
      "INFO:root:Epoch: 11, Batch: 800, Loss: 0.0952\n",
      "INFO:root:Epoch: 11, Batch: 900, Loss: 0.0474\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:9/20 = 0.450000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:35/40 = 0.875000\n",
      "INFO:root:Beginning Epoch 12\n",
      "INFO:root:Epoch: 12, Batch: 100, Loss: 0.0362\n",
      "INFO:root:Epoch: 12, Batch: 200, Loss: 0.1021\n",
      "INFO:root:Epoch: 12, Batch: 300, Loss: 0.0334\n",
      "INFO:root:Epoch: 12, Batch: 400, Loss: 0.0360\n",
      "INFO:root:Epoch: 12, Batch: 500, Loss: 0.0629\n",
      "INFO:root:Epoch: 12, Batch: 600, Loss: 0.1108\n",
      "INFO:root:Epoch: 12, Batch: 700, Loss: 0.0186\n",
      "INFO:root:Epoch: 12, Batch: 800, Loss: 0.0534\n",
      "INFO:root:Epoch: 12, Batch: 900, Loss: 0.0923\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:9/20 = 0.450000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:31/40 = 0.775000\n",
      "INFO:root:Beginning Epoch 13\n",
      "INFO:root:Epoch: 13, Batch: 100, Loss: 0.1447\n",
      "INFO:root:Epoch: 13, Batch: 200, Loss: 0.0256\n",
      "INFO:root:Epoch: 13, Batch: 300, Loss: 0.0365\n",
      "INFO:root:Epoch: 13, Batch: 400, Loss: 0.0581\n",
      "INFO:root:Epoch: 13, Batch: 500, Loss: 0.1681\n",
      "INFO:root:Epoch: 13, Batch: 600, Loss: 0.0810\n",
      "INFO:root:Epoch: 13, Batch: 700, Loss: 0.0285\n",
      "INFO:root:Epoch: 13, Batch: 800, Loss: 0.0515\n",
      "INFO:root:Epoch: 13, Batch: 900, Loss: 0.0350\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:10/20 = 0.500000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:31/40 = 0.775000\n",
      "INFO:root:Beginning Epoch 14\n",
      "INFO:root:Epoch: 14, Batch: 100, Loss: 0.1092\n",
      "INFO:root:Epoch: 14, Batch: 200, Loss: 0.0657\n",
      "INFO:root:Epoch: 14, Batch: 300, Loss: 0.0971\n",
      "INFO:root:Epoch: 14, Batch: 400, Loss: 0.0719\n",
      "INFO:root:Epoch: 14, Batch: 500, Loss: 0.0488\n",
      "INFO:root:Epoch: 14, Batch: 600, Loss: 0.0294\n",
      "INFO:root:Epoch: 14, Batch: 700, Loss: 0.0370\n",
      "INFO:root:Epoch: 14, Batch: 800, Loss: 0.1047\n",
      "INFO:root:Epoch: 14, Batch: 900, Loss: 0.1050\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:11/20 = 0.550000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:33/40 = 0.825000\n",
      "INFO:root:Beginning Epoch 15\n",
      "INFO:root:Epoch: 15, Batch: 100, Loss: 0.0505\n",
      "INFO:root:Epoch: 15, Batch: 200, Loss: 0.0350\n",
      "INFO:root:Epoch: 15, Batch: 300, Loss: 0.1205\n",
      "INFO:root:Epoch: 15, Batch: 400, Loss: 0.2116\n",
      "INFO:root:Epoch: 15, Batch: 500, Loss: 0.1204\n",
      "INFO:root:Epoch: 15, Batch: 600, Loss: 0.0428\n",
      "INFO:root:Epoch: 15, Batch: 700, Loss: 0.1625\n",
      "INFO:root:Epoch: 15, Batch: 800, Loss: 0.0484\n",
      "INFO:root:Epoch: 15, Batch: 900, Loss: 0.0199\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:10/20 = 0.500000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:35/40 = 0.875000\n",
      "INFO:root:Beginning Epoch 16\n",
      "INFO:root:Epoch: 16, Batch: 100, Loss: 0.0448\n",
      "INFO:root:Epoch: 16, Batch: 200, Loss: 0.1116\n",
      "INFO:root:Epoch: 16, Batch: 300, Loss: 0.0993\n",
      "INFO:root:Epoch: 16, Batch: 400, Loss: 0.1062\n",
      "INFO:root:Epoch: 16, Batch: 500, Loss: 0.0239\n",
      "INFO:root:Epoch: 16, Batch: 600, Loss: 0.0233\n",
      "INFO:root:Epoch: 16, Batch: 700, Loss: 0.0365\n",
      "INFO:root:Epoch: 16, Batch: 800, Loss: 0.0486\n",
      "INFO:root:Epoch: 16, Batch: 900, Loss: 0.0180\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:9/20 = 0.450000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:31/40 = 0.775000\n",
      "INFO:root:Beginning Epoch 17\n",
      "INFO:root:Epoch: 17, Batch: 100, Loss: 0.0328\n",
      "INFO:root:Epoch: 17, Batch: 200, Loss: 0.0433\n",
      "INFO:root:Epoch: 17, Batch: 300, Loss: 0.0928\n",
      "INFO:root:Epoch: 17, Batch: 400, Loss: 0.1188\n",
      "INFO:root:Epoch: 17, Batch: 500, Loss: 0.0425\n",
      "INFO:root:Epoch: 17, Batch: 600, Loss: 0.0628\n",
      "INFO:root:Epoch: 17, Batch: 700, Loss: 0.0414\n",
      "INFO:root:Epoch: 17, Batch: 800, Loss: 0.0242\n",
      "INFO:root:Epoch: 17, Batch: 900, Loss: 0.0372\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:11/20 = 0.550000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:34/40 = 0.850000\n",
      "INFO:root:Beginning Epoch 18\n",
      "INFO:root:Epoch: 18, Batch: 100, Loss: 0.0384\n",
      "INFO:root:Epoch: 18, Batch: 200, Loss: 0.0370\n",
      "INFO:root:Epoch: 18, Batch: 300, Loss: 0.0579\n",
      "INFO:root:Epoch: 18, Batch: 400, Loss: 0.0329\n",
      "INFO:root:Epoch: 18, Batch: 500, Loss: 0.0391\n",
      "INFO:root:Epoch: 18, Batch: 600, Loss: 0.0711\n",
      "INFO:root:Epoch: 18, Batch: 700, Loss: 0.0536\n",
      "INFO:root:Epoch: 18, Batch: 800, Loss: 0.0432\n",
      "INFO:root:Epoch: 18, Batch: 900, Loss: 0.0571\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:11/20 = 0.550000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:35/40 = 0.875000\n",
      "INFO:root:Beginning Epoch 19\n",
      "INFO:root:Epoch: 19, Batch: 100, Loss: 0.0283\n",
      "INFO:root:Epoch: 19, Batch: 200, Loss: 0.0357\n",
      "INFO:root:Epoch: 19, Batch: 300, Loss: 0.0353\n",
      "INFO:root:Epoch: 19, Batch: 400, Loss: 0.0438\n",
      "INFO:root:Epoch: 19, Batch: 500, Loss: 0.0962\n",
      "INFO:root:Epoch: 19, Batch: 600, Loss: 0.0653\n",
      "INFO:root:Epoch: 19, Batch: 700, Loss: 0.0824\n",
      "INFO:root:Epoch: 19, Batch: 800, Loss: 0.0442\n",
      "INFO:root:Epoch: 19, Batch: 900, Loss: 0.0349\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:12/20 = 0.600000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:36/40 = 0.900000\n",
      "INFO:root:Beginning Epoch 20\n",
      "INFO:root:Epoch: 20, Batch: 100, Loss: 0.0790\n",
      "INFO:root:Epoch: 20, Batch: 200, Loss: 0.0881\n",
      "INFO:root:Epoch: 20, Batch: 300, Loss: 0.1307\n",
      "INFO:root:Epoch: 20, Batch: 400, Loss: 0.0863\n",
      "INFO:root:Epoch: 20, Batch: 500, Loss: 0.0269\n",
      "INFO:root:Epoch: 20, Batch: 600, Loss: 0.0342\n",
      "INFO:root:Epoch: 20, Batch: 700, Loss: 0.0443\n",
      "INFO:root:Epoch: 20, Batch: 800, Loss: 0.0465\n",
      "INFO:root:Epoch: 20, Batch: 900, Loss: 0.0349\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:11/20 = 0.550000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:36/40 = 0.900000\n",
      "INFO:root:Beginning Epoch 21\n",
      "INFO:root:Epoch: 21, Batch: 100, Loss: 0.2121\n",
      "INFO:root:Epoch: 21, Batch: 200, Loss: 0.0369\n",
      "INFO:root:Epoch: 21, Batch: 300, Loss: 0.0995\n",
      "INFO:root:Epoch: 21, Batch: 400, Loss: 0.0593\n",
      "INFO:root:Epoch: 21, Batch: 500, Loss: 0.0420\n",
      "INFO:root:Epoch: 21, Batch: 600, Loss: 0.0505\n",
      "INFO:root:Epoch: 21, Batch: 700, Loss: 0.0453\n",
      "INFO:root:Epoch: 21, Batch: 800, Loss: 0.0572\n",
      "INFO:root:Epoch: 21, Batch: 900, Loss: 0.1175\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:14/20 = 0.700000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:37/40 = 0.925000\n",
      "INFO:root:Beginning Epoch 22\n",
      "INFO:root:Epoch: 22, Batch: 100, Loss: 0.0394\n",
      "INFO:root:Epoch: 22, Batch: 200, Loss: 0.0597\n",
      "INFO:root:Epoch: 22, Batch: 300, Loss: 0.0286\n",
      "INFO:root:Epoch: 22, Batch: 400, Loss: 0.0380\n",
      "INFO:root:Epoch: 22, Batch: 500, Loss: 0.0499\n",
      "INFO:root:Epoch: 22, Batch: 600, Loss: 0.0953\n",
      "INFO:root:Epoch: 22, Batch: 700, Loss: 0.0238\n",
      "INFO:root:Epoch: 22, Batch: 800, Loss: 0.0265\n",
      "INFO:root:Epoch: 22, Batch: 900, Loss: 0.0412\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:13/20 = 0.650000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:37/40 = 0.925000\n",
      "INFO:root:Beginning Epoch 23\n",
      "INFO:root:Epoch: 23, Batch: 100, Loss: 0.0303\n",
      "INFO:root:Epoch: 23, Batch: 200, Loss: 0.0293\n",
      "INFO:root:Epoch: 23, Batch: 300, Loss: 0.0440\n",
      "INFO:root:Epoch: 23, Batch: 400, Loss: 0.0453\n",
      "INFO:root:Epoch: 23, Batch: 500, Loss: 0.0242\n",
      "INFO:root:Epoch: 23, Batch: 600, Loss: 0.0453\n",
      "INFO:root:Epoch: 23, Batch: 700, Loss: 0.0262\n",
      "INFO:root:Epoch: 23, Batch: 800, Loss: 0.0307\n",
      "INFO:root:Epoch: 23, Batch: 900, Loss: 0.1070\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:11/20 = 0.550000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:36/40 = 0.900000\n",
      "INFO:root:Beginning Epoch 24\n",
      "INFO:root:Epoch: 24, Batch: 100, Loss: 0.0521\n",
      "INFO:root:Epoch: 24, Batch: 200, Loss: 0.0818\n",
      "INFO:root:Epoch: 24, Batch: 300, Loss: 0.1132\n",
      "INFO:root:Epoch: 24, Batch: 400, Loss: 0.0460\n",
      "INFO:root:Epoch: 24, Batch: 500, Loss: 0.0258\n",
      "INFO:root:Epoch: 24, Batch: 600, Loss: 0.0320\n",
      "INFO:root:Epoch: 24, Batch: 700, Loss: 0.0575\n",
      "INFO:root:Epoch: 24, Batch: 800, Loss: 0.0488\n",
      "INFO:root:Epoch: 24, Batch: 900, Loss: 0.0371\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:13/20 = 0.650000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:37/40 = 0.925000\n",
      "INFO:root:Beginning Epoch 25\n",
      "INFO:root:Epoch: 25, Batch: 100, Loss: 0.1009\n",
      "INFO:root:Epoch: 25, Batch: 200, Loss: 0.0389\n",
      "INFO:root:Epoch: 25, Batch: 300, Loss: 0.0608\n",
      "INFO:root:Epoch: 25, Batch: 400, Loss: 0.0434\n",
      "INFO:root:Epoch: 25, Batch: 500, Loss: 0.0505\n",
      "INFO:root:Epoch: 25, Batch: 600, Loss: 0.0490\n",
      "INFO:root:Epoch: 25, Batch: 700, Loss: 0.0155\n",
      "INFO:root:Epoch: 25, Batch: 800, Loss: 0.1609\n",
      "INFO:root:Epoch: 25, Batch: 900, Loss: 0.0310\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:13/20 = 0.650000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:39/40 = 0.975000\n",
      "INFO:root:Beginning Epoch 26\n",
      "INFO:root:Epoch: 26, Batch: 100, Loss: 0.0611\n",
      "INFO:root:Epoch: 26, Batch: 200, Loss: 0.1117\n",
      "INFO:root:Epoch: 26, Batch: 300, Loss: 0.0407\n",
      "INFO:root:Epoch: 26, Batch: 400, Loss: 0.0287\n",
      "INFO:root:Epoch: 26, Batch: 500, Loss: 0.0374\n",
      "INFO:root:Epoch: 26, Batch: 600, Loss: 0.0421\n",
      "INFO:root:Epoch: 26, Batch: 700, Loss: 0.1083\n",
      "INFO:root:Epoch: 26, Batch: 800, Loss: 0.0188\n",
      "INFO:root:Epoch: 26, Batch: 900, Loss: 0.1092\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:13/20 = 0.650000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:35/40 = 0.875000\n",
      "INFO:root:Beginning Epoch 27\n",
      "INFO:root:Epoch: 27, Batch: 100, Loss: 0.1176\n",
      "INFO:root:Epoch: 27, Batch: 200, Loss: 0.1762\n",
      "INFO:root:Epoch: 27, Batch: 300, Loss: 0.0362\n",
      "INFO:root:Epoch: 27, Batch: 400, Loss: 0.0367\n",
      "INFO:root:Epoch: 27, Batch: 500, Loss: 0.0441\n",
      "INFO:root:Epoch: 27, Batch: 600, Loss: 0.0414\n",
      "INFO:root:Epoch: 27, Batch: 700, Loss: 0.0979\n",
      "INFO:root:Epoch: 27, Batch: 800, Loss: 0.0348\n",
      "INFO:root:Epoch: 27, Batch: 900, Loss: 0.0532\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:15/20 = 0.750000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:35/40 = 0.875000\n",
      "INFO:root:Beginning Epoch 28\n",
      "INFO:root:Epoch: 28, Batch: 100, Loss: 0.0850\n",
      "INFO:root:Epoch: 28, Batch: 200, Loss: 0.0456\n",
      "INFO:root:Epoch: 28, Batch: 300, Loss: 0.0407\n",
      "INFO:root:Epoch: 28, Batch: 400, Loss: 0.0249\n",
      "INFO:root:Epoch: 28, Batch: 500, Loss: 0.0593\n",
      "INFO:root:Epoch: 28, Batch: 600, Loss: 0.0375\n",
      "INFO:root:Epoch: 28, Batch: 700, Loss: 0.0291\n",
      "INFO:root:Epoch: 28, Batch: 800, Loss: 0.0904\n",
      "INFO:root:Epoch: 28, Batch: 900, Loss: 0.0430\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:14/20 = 0.700000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:35/40 = 0.875000\n",
      "INFO:root:Beginning Epoch 29\n",
      "INFO:root:Epoch: 29, Batch: 100, Loss: 0.0235\n",
      "INFO:root:Epoch: 29, Batch: 200, Loss: 0.0252\n",
      "INFO:root:Epoch: 29, Batch: 300, Loss: 0.0322\n",
      "INFO:root:Epoch: 29, Batch: 400, Loss: 0.0666\n",
      "INFO:root:Epoch: 29, Batch: 500, Loss: 0.0434\n",
      "INFO:root:Epoch: 29, Batch: 600, Loss: 0.0261\n",
      "INFO:root:Epoch: 29, Batch: 700, Loss: 0.0342\n",
      "INFO:root:Epoch: 29, Batch: 800, Loss: 0.0447\n",
      "INFO:root:Epoch: 29, Batch: 900, Loss: 0.0230\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:14/20 = 0.700000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:38/40 = 0.950000\n",
      "INFO:root:Beginning Epoch 30\n",
      "INFO:root:Epoch: 30, Batch: 100, Loss: 0.0271\n",
      "INFO:root:Epoch: 30, Batch: 200, Loss: 0.0203\n",
      "INFO:root:Epoch: 30, Batch: 300, Loss: 0.0537\n",
      "INFO:root:Epoch: 30, Batch: 400, Loss: 0.0593\n",
      "INFO:root:Epoch: 30, Batch: 500, Loss: 0.0423\n",
      "INFO:root:Epoch: 30, Batch: 600, Loss: 0.0428\n",
      "INFO:root:Epoch: 30, Batch: 700, Loss: 0.0362\n",
      "INFO:root:Epoch: 30, Batch: 800, Loss: 0.0265\n",
      "INFO:root:Epoch: 30, Batch: 900, Loss: 0.1635\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:14/20 = 0.700000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:34/40 = 0.850000\n",
      "INFO:root:Beginning Epoch 31\n",
      "INFO:root:Epoch: 31, Batch: 100, Loss: 0.1799\n",
      "INFO:root:Epoch: 31, Batch: 200, Loss: 0.0910\n",
      "INFO:root:Epoch: 31, Batch: 300, Loss: 0.0482\n",
      "INFO:root:Epoch: 31, Batch: 400, Loss: 0.0535\n",
      "INFO:root:Epoch: 31, Batch: 500, Loss: 0.0986\n",
      "INFO:root:Epoch: 31, Batch: 600, Loss: 0.0502\n",
      "INFO:root:Epoch: 31, Batch: 700, Loss: 0.0910\n",
      "INFO:root:Epoch: 31, Batch: 800, Loss: 0.0462\n",
      "INFO:root:Epoch: 31, Batch: 900, Loss: 0.0807\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:14/20 = 0.700000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:36/40 = 0.900000\n",
      "INFO:root:Beginning Epoch 32\n",
      "INFO:root:Epoch: 32, Batch: 100, Loss: 0.0874\n",
      "INFO:root:Epoch: 32, Batch: 200, Loss: 0.0541\n",
      "INFO:root:Epoch: 32, Batch: 300, Loss: 0.1551\n",
      "INFO:root:Epoch: 32, Batch: 400, Loss: 0.0303\n",
      "INFO:root:Epoch: 32, Batch: 500, Loss: 0.0331\n",
      "INFO:root:Epoch: 32, Batch: 600, Loss: 0.0405\n",
      "INFO:root:Epoch: 32, Batch: 700, Loss: 0.0593\n",
      "INFO:root:Epoch: 32, Batch: 800, Loss: 0.0514\n",
      "INFO:root:Epoch: 32, Batch: 900, Loss: 0.0512\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:14/20 = 0.700000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:34/40 = 0.850000\n",
      "INFO:root:Beginning Epoch 33\n",
      "INFO:root:Epoch: 33, Batch: 100, Loss: 0.0451\n",
      "INFO:root:Epoch: 33, Batch: 200, Loss: 0.0229\n",
      "INFO:root:Epoch: 33, Batch: 300, Loss: 0.0285\n",
      "INFO:root:Epoch: 33, Batch: 400, Loss: 0.0599\n",
      "INFO:root:Epoch: 33, Batch: 500, Loss: 0.0500\n",
      "INFO:root:Epoch: 33, Batch: 600, Loss: 0.0537\n",
      "INFO:root:Epoch: 33, Batch: 700, Loss: 0.0899\n",
      "INFO:root:Epoch: 33, Batch: 800, Loss: 0.1021\n",
      "INFO:root:Epoch: 33, Batch: 900, Loss: 0.0277\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:14/20 = 0.700000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:37/40 = 0.925000\n",
      "INFO:root:Beginning Epoch 34\n",
      "INFO:root:Epoch: 34, Batch: 100, Loss: 0.0490\n",
      "INFO:root:Epoch: 34, Batch: 200, Loss: 0.0402\n",
      "INFO:root:Epoch: 34, Batch: 300, Loss: 0.0306\n",
      "INFO:root:Epoch: 34, Batch: 400, Loss: 0.0422\n",
      "INFO:root:Epoch: 34, Batch: 500, Loss: 0.0898\n",
      "INFO:root:Epoch: 34, Batch: 600, Loss: 0.0481\n",
      "INFO:root:Epoch: 34, Batch: 700, Loss: 0.0790\n",
      "INFO:root:Epoch: 34, Batch: 800, Loss: 0.0310\n",
      "INFO:root:Epoch: 34, Batch: 900, Loss: 0.0927\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:13/20 = 0.650000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:36/40 = 0.900000\n",
      "INFO:root:Beginning Epoch 35\n",
      "INFO:root:Epoch: 35, Batch: 100, Loss: 0.0741\n",
      "INFO:root:Epoch: 35, Batch: 200, Loss: 0.0218\n",
      "INFO:root:Epoch: 35, Batch: 300, Loss: 0.0494\n",
      "INFO:root:Epoch: 35, Batch: 400, Loss: 0.0405\n",
      "INFO:root:Epoch: 35, Batch: 500, Loss: 0.0387\n",
      "INFO:root:Epoch: 35, Batch: 600, Loss: 0.0271\n",
      "INFO:root:Epoch: 35, Batch: 700, Loss: 0.0276\n",
      "INFO:root:Epoch: 35, Batch: 800, Loss: 0.0360\n",
      "INFO:root:Epoch: 35, Batch: 900, Loss: 0.0531\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:13/20 = 0.650000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:34/40 = 0.850000\n",
      "INFO:root:Beginning Epoch 36\n",
      "INFO:root:Epoch: 36, Batch: 100, Loss: 0.0342\n",
      "INFO:root:Epoch: 36, Batch: 200, Loss: 0.0217\n",
      "INFO:root:Epoch: 36, Batch: 300, Loss: 0.0605\n",
      "INFO:root:Epoch: 36, Batch: 400, Loss: 0.0624\n",
      "INFO:root:Epoch: 36, Batch: 500, Loss: 0.0324\n",
      "INFO:root:Epoch: 36, Batch: 600, Loss: 0.0433\n",
      "INFO:root:Epoch: 36, Batch: 700, Loss: 0.1037\n",
      "INFO:root:Epoch: 36, Batch: 800, Loss: 0.0274\n",
      "INFO:root:Epoch: 36, Batch: 900, Loss: 0.0530\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:14/20 = 0.700000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:34/40 = 0.850000\n",
      "INFO:root:Beginning Epoch 37\n",
      "INFO:root:Epoch: 37, Batch: 100, Loss: 0.1049\n",
      "INFO:root:Epoch: 37, Batch: 200, Loss: 0.0375\n",
      "INFO:root:Epoch: 37, Batch: 300, Loss: 0.0209\n",
      "INFO:root:Epoch: 37, Batch: 400, Loss: 0.0312\n",
      "INFO:root:Epoch: 37, Batch: 500, Loss: 0.0881\n",
      "INFO:root:Epoch: 37, Batch: 600, Loss: 0.0202\n",
      "INFO:root:Epoch: 37, Batch: 700, Loss: 0.0376\n",
      "INFO:root:Epoch: 37, Batch: 800, Loss: 0.0548\n",
      "INFO:root:Epoch: 37, Batch: 900, Loss: 0.0384\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:14/20 = 0.700000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:36/40 = 0.900000\n",
      "INFO:root:Beginning Epoch 38\n",
      "INFO:root:Epoch: 38, Batch: 100, Loss: 0.0691\n",
      "INFO:root:Epoch: 38, Batch: 200, Loss: 0.0401\n",
      "INFO:root:Epoch: 38, Batch: 300, Loss: 0.0324\n",
      "INFO:root:Epoch: 38, Batch: 400, Loss: 0.0462\n",
      "INFO:root:Epoch: 38, Batch: 500, Loss: 0.0588\n",
      "INFO:root:Epoch: 38, Batch: 600, Loss: 0.0515\n",
      "INFO:root:Epoch: 38, Batch: 700, Loss: 0.0600\n",
      "INFO:root:Epoch: 38, Batch: 800, Loss: 0.0463\n",
      "INFO:root:Epoch: 38, Batch: 900, Loss: 0.0704\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:12/20 = 0.600000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:34/40 = 0.850000\n",
      "INFO:root:Beginning Epoch 39\n",
      "INFO:root:Epoch: 39, Batch: 100, Loss: 0.0607\n",
      "INFO:root:Epoch: 39, Batch: 200, Loss: 0.1097\n",
      "INFO:root:Epoch: 39, Batch: 300, Loss: 0.1166\n",
      "INFO:root:Epoch: 39, Batch: 400, Loss: 0.0927\n",
      "INFO:root:Epoch: 39, Batch: 500, Loss: 0.1043\n",
      "INFO:root:Epoch: 39, Batch: 600, Loss: 0.0619\n",
      "INFO:root:Epoch: 39, Batch: 700, Loss: 0.1758\n",
      "INFO:root:Epoch: 39, Batch: 800, Loss: 0.1622\n",
      "INFO:root:Epoch: 39, Batch: 900, Loss: 0.0561\n",
      "INFO:root:Validating on sparse validation set...\n",
      "INFO:root:14/20 = 0.700000\n",
      "INFO:root:Validating on annotated validation set...\n",
      "INFO:root:36/40 = 0.900000\n",
      "INFO:root:Beginning Epoch 40\n",
      "INFO:root:Epoch: 40, Batch: 100, Loss: 0.1570\n",
      "INFO:root:Epoch: 40, Batch: 200, Loss: 0.0473\n",
      "INFO:root:Epoch: 40, Batch: 300, Loss: 0.0345\n",
      "INFO:root:Epoch: 40, Batch: 400, Loss: 0.0505\n",
      "INFO:root:Epoch: 40, Batch: 500, Loss: 0.0213\n",
      "INFO:root:Epoch: 40, Batch: 600, Loss: 0.0238\n",
      "INFO:root:Epoch: 40, Batch: 700, Loss: 0.0934\n"
     ]
    }
   ],
   "source": [
    "best_iou_sparse = 0.0\n",
    "best_iou_annotated = 0.0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    logging.info('Beginning Epoch {:02d}'.format(epoch))\n",
    "\n",
    "    if epoch in lr_step:\n",
    "        print(lr_step)\n",
    "        lr = lr * lr_step_coeff\n",
    "        print('Drop LR to', lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    train_results = train(\n",
    "        epoch, net, device, train_data, optimizer, batches_per_epoch, vis=vis\n",
    "    )\n",
    "\n",
    "    # Log training losses to tensorboard\n",
    "    tb.add_scalar('loss/train_loss', train_results['loss'], epoch)\n",
    "    for n, l in train_results['losses'].items():\n",
    "        tb.add_scalar('train_loss/' + n, l, epoch)\n",
    "\n",
    "    # Run Validation\n",
    "    logging.info('Validating on sparse validation set...')\n",
    "    test_results = validate(net, device, val_data_sparse, use_sparse_loss=True)\n",
    "    logging.info('%d/%d = %f' % (test_results['correct'],\n",
    "                 test_results['correct'] + test_results['failed'],\n",
    "                 test_results['correct']/(test_results['correct']+test_results['failed'])\n",
    "                 ))\n",
    "\n",
    "    # Log validation results to tensorbaord\n",
    "    tb.add_scalar(\n",
    "        'loss/IOU_sparse',\n",
    "        test_results['correct'] / (test_results['correct'] + test_results['failed']),\n",
    "        epoch\n",
    "    )\n",
    "    tb.add_scalar('loss/val_loss_sparse', test_results['loss'], epoch)\n",
    "    for n, l in test_results['losses'].items():\n",
    "        tb.add_scalar('val_loss_sparse/' + n, l, epoch)\n",
    "\n",
    "    # Save best performing network\n",
    "    iou_sparse = test_results['correct'] / (test_results['correct'] + test_results['failed'])\n",
    "\n",
    "    logging.info('Validating on annotated validation set...')\n",
    "    test_results = validate(net, device, val_data_annotated, use_sparse_loss=False)  \n",
    "    logging.info('%d/%d = %f' % (test_results['correct'],\n",
    "                                 test_results['correct'] + test_results['failed'],\n",
    "                                 test_results['correct']/(test_results['correct']+test_results['failed'])\n",
    "                                ))\n",
    "\n",
    "    # Log validation results to tensorbaord\n",
    "    tb.add_scalar(\n",
    "        'loss/IOU_annotated',\n",
    "        test_results['correct'] / (test_results['correct'] + test_results['failed']),\n",
    "        epoch\n",
    "    )\n",
    "    tb.add_scalar('loss/val_loss_annotated', test_results['loss'], epoch)\n",
    "    for n, l in test_results['losses'].items():\n",
    "        tb.add_scalar('val_loss_annotated/' + n, l, epoch)\n",
    "\n",
    "    # Save best performing network\n",
    "    iou_annotated = test_results['correct'] / (test_results['correct'] + test_results['failed'])\n",
    "    \n",
    "    if iou_sparse > best_iou_sparse or iou_annotated>best_iou_annotated or epoch == 0 or (epoch % force_save_every) == 0:\n",
    "        torch.save(\n",
    "            net,\n",
    "            os.path.join(save_folder, 'epoch_%02d_iou_S_%0.2f_iou_A_%0.2f' % (epoch, iou_sparse, iou_annotated))\n",
    "        )\n",
    "        torch.save(net.state_dict(), os.path.join(save_folder, 'epoch_%02d_iou_S_%0.2f_iou_A_%0.2f_statedict.pt' % (epoch, iou_sparse, iou_annotated)))\n",
    "        best_iou_sparse = max(iou_sparse, best_iou_sparse)\n",
    "        best_iou_annotated = max(iou_annotated, best_iou_annotated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peggnet",
   "language": "python",
   "name": "peggnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
